# Desmoke
Multiscale deep desmoking for laparoscopic surgery 

## Abstract
<p align="justify">
In minimally invasive surgery, smoke generated by such as electrocautery and laser ablation deteriorates image quality severely. This creates discomfortable view for the surgeon which may increase surgical risk and degrade the performance of computer assisted surgery algorithms such as segmentation, reconstruction, tracking, etc. Therefore, real-time smoke removal is required to keep a clear field of view. In this paper, we propose a real-time smoke removal approach based on Convolutional Neural Network (CNN). An encoder-decoder architecture with Laplacian image pyramid decomposition input strategy is proposed. This is an end-to-end network which takes the smoke image and its Laplacian image pyramid decomposition as inputs, and outputs a smoke free image directly without relying on any physical models or estimation of intermediate parameters. This design can be further embedded to deep learning based follow-up image guided surgery processes such as segmentation and tracking tasks easily. A dataset with synthetic smoke images generated from Blender and Adobe Photoshop is employed for training the network. The result is evaluated quantitatively on synthetic images and qualitatively on a laparoscopic dataset degraded with real smoke. Our proposed method can eliminate smoke effectively while preserving the original colors and reaches 26 fps for a video of size 512 Ã— 512 on our training machine. The obtained results not only demonstrate the efficiency and effectiveness of the proposed CNN structure, but also prove the potency of training the network on synthetic dataset.</p>

## Sample Result
![alt text](https://github.com/ahme0307/streoscene/blob/master/readme/image002.PNG)

## Network
![alt text](https://github.com/ahme0307/streoscene/blob/master/readme/fully2.png)

## How to train 
- To train the network <a href="https://github.com/ahme0307/streoscene/blob/master/Roboscene.ipynb">Desmoke.ipynb</a>   


> python main_run.py

- For intractive training and visualization checkout the jupyter notebook: <a href="https://github.com/ahme0307/streoscene/blob/master/Roboscene.ipynb">Roboscene.ipynb</a>  

## Reference
If you find this code useful please cite
>Mohammed, Ahmed, et al. "StreoScenNet: surgical stereo robotic scene segmentation." Medical Imaging 2019: Image-Guided Procedures, Robotic Interventions, and Modeling. Vol. 10951. International Society for Optics and Photonics, 2019.

@inproceedings{mohammed2019streoscennet,
  title={StreoScenNet: surgical stereo robotic scene segmentation},
  author={Mohammed, Ahmed and Yildirim, Sule and Farup, Ivar and Pedersen, Marius and Hovde, {\O}istein},
  booktitle={Medical Imaging 2019: Image-Guided Procedures, Robotic Interventions, and Modeling},
  volume={10951},
  pages={109510P},
  year={2019},
  organization={International Society for Optics and Photonics}
}
